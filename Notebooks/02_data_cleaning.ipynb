{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c772ad1d-6bdb-4aca-b295-b7947ea6975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Spark and DataFrame operations\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003f779-2104-4b72-82a0-7c1eb6d28eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session with AWS S3 configurations\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Data Cleaning\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8278014-a5a4-44e0-81a0-3fe3389d0a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaning\n",
      "<pyspark.sql.session.SparkSession object at 0x79b02598cbd0>\n"
     ]
    }
   ],
   "source": [
    "# Print the application name and Spark context information\n",
    "print(spark.sparkContext.appName)\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2078f88a-772c-4dc0-8081-4f55f4068e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Spark context from the Spark session\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c349a7-717c-44d1-b1b2-25865de3d9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the version of Spark\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e126db-d541-4fe5-915d-7c30e69119d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the Python version used by Spark\n",
    "sc.pythonVer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad2ff0-4869-4e77-a73d-857f40c75b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the master URL of the Spark cluster\n",
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d078f-20ca-45fb-aa6e-b64fc7ad2a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary types for DataFrame schema definition\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f878a4ab-433e-4080-a8d2-05a8d29a7cb0",
   "metadata": {},
   "source": [
    "### News Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341dd0f-a600-4c72-bf5f-e8b350f0a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the news data DataFrame\n",
    "data_schema = StructType([\n",
    "    StructField(\"No\", StringType(), True),\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Article_title\", StringType(), True),\n",
    "    StructField(\"Stock_symbol\", StringType(), True),\n",
    "    StructField(\"Url\", StringType(), True),\n",
    "    StructField(\"Publisher\", StringType(), True),\n",
    "    StructField(\"Author\", StringType(), True),\n",
    "    StructField(\"Article\", StringType(), True),\n",
    "    StructField(\"Lsa_summary\", StringType(), True),\n",
    "    StructField(\"Luhn_summary\", StringType(), True),\n",
    "    StructField(\"Textrank_summary\", StringType(), True),\n",
    "    StructField(\"Lexrank_summary\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2a923-abc1-4ca2-9f53-29047d710838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the S3 path for the news data CSV file\n",
    "bucket = 'fnf-bucket' \n",
    "object_path = 'bronze/stock_news/nasdaq_exteral_data.csv' \n",
    "s3a_path = f's3a://{bucket}/{object_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3754eb-d509-4b33-8d35-3b0212c3a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the news data from S3 into a DataFrame with the specified schema\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"multiline\", \"true\") \\\n",
    "    .schema(data_schema) \\\n",
    "    .load(s3a_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92954b1d-28cf-40c1-9fdd-83b7b5ac0de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- No: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Article_title: string (nullable = true)\n",
      " |-- Stock_symbol: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Publisher: string (nullable = true)\n",
      " |-- Author: string (nullable = true)\n",
      " |-- Article: string (nullable = true)\n",
      " |-- Lsa_summary: string (nullable = true)\n",
      " |-- Luhn_summary: string (nullable = true)\n",
      " |-- Textrank_summary: string (nullable = true)\n",
      " |-- Lexrank_summary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the loaded DataFrame\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe6175-a1b8-4ade-a7b0-5a61eb57f3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns from the DataFrame\n",
    "df = df.drop(F.col('Publisher'), F.col('Author'), F.col('Luhn_summary'), F.col('Textrank_summary'), F.col('Lexrank_summary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbfbe7-eba8-463f-a618-576e394bbf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- No: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Article_title: string (nullable = true)\n",
      " |-- Stock_symbol: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Article: string (nullable = true)\n",
      " |-- Lsa_summary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema after dropping columns\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a414cc98-5431-430c-85de-ddcabe80b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries for data manipulation\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c9d761-a0d4-4c01-a169-a5c9cf9be3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the URL to fetch S&P 500 companies data\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f43ed4-a7fa-4a73-b6da-13c2e4c84e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.11/site-packages (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Install the lxml library for parsing HTML\n",
    "! pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd86ce-86e1-4796-9c1c-865a38e4f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the S&P 500 companies data from the URL\n",
    "response = requests.get(url, headers=headers)\n",
    "tables = pd.read_html(StringIO(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832a868-2c09-4e16-a48a-5cb85ff64ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first table from the fetched data\n",
    "sp500_table = tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c653ed-0208-4f8c-a09f-52473e7752d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of stock symbols from the S&P 500 table\n",
    "stock_list = sp500_table['Symbol'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f6a7a-bb1a-4c6a-9e91-942de3415a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the news DataFrame to include only S&P 500 stocks\n",
    "sp500_df = df.where(F.col('Stock_symbol').isin(stock_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5bc1f6-9e2f-4723-a49e-1c592680c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast columns to appropriate types for further processing\n",
    "sp500_df = sp500_df.withColumn(\n",
    "    \"No\", F.col(\"No\").cast(\"integer\")\n",
    ").withColumn(\n",
    "    \"Date\", F.to_date(F.col(\"Date\"), \"yyyy-MM-dd HH:mm:ss z\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9556d4b-3e62-483a-b7f7-69510ca9e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values from the DataFrame\n",
    "df_clean = sp500_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4a0c78-82e8-495e-af0f-b406bfd240d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- No: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Article_title: string (nullable = true)\n",
      " |-- Stock_symbol: string (nullable = true)\n",
      " |-- Url: string (nullable = true)\n",
      " |-- Article: string (nullable = true)\n",
      " |-- Lsa_summary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the cleaned DataFrame\n",
    "df_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3200dc0-4ebd-4217-a87d-c35bf415bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the cleaned DataFrame to S3 in Parquet format, partitioned by stock symbol\n",
    "df_clean.write \\\n",
    "    .mode('overwrite') \\\n",
    "    .option('compression', 'snappy') \\\n",
    "    .partitionBy('Stock_symbol') \\\n",
    "    .parquet('s3a://fnf-bucket/silver/news_data_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedc0e5d-c8e0-48c4-802e-62600369e4c1",
   "metadata": {},
   "source": [
    "### Stocks Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac28e10-0ea5-4daf-b4ae-a5918c397a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input path for stock price data\n",
    "input_path = \"s3a://fnf-bucket/bronze/stock_price/full_history/*.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca293677-cb66-45b7-9a85-b526d6cdf93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stock price data from S3 into a DataFrame\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d2cebd-a903-4805-bda1-e5c5331c0549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize column names (handle case sensitivity and spaces)\n",
    "for col_name in df.columns:\n",
    "    df = df.withColumnRenamed(col_name, col_name.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff62af-fb72-41b1-88b1-177a19eb4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and cast columns by name for further processing\n",
    "df = df.select(\n",
    "    F.to_date(F.col(\"Date\"), \"yyyy-MM-dd\").alias(\"Date\"),\n",
    "    F.col(\"Open\").cast(DoubleType()).alias(\"Open\"),\n",
    "    F.col(\"High\").cast(DoubleType()).alias(\"High\"),\n",
    "    F.col(\"Low\").cast(DoubleType()).alias(\"Low\"),\n",
    "    F.col(\"Close\").cast(DoubleType()).alias(\"Close\"),\n",
    "    F.col(\"Adj Close\").cast(DoubleType()).alias(\"Adj Close\"),\n",
    "    F.col(\"Volume\").cast(LongType()).alias(\"Volume\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36aa825-d569-4dd2-8416-5f37bfa3f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add stock symbol from filename to the DataFrame\n",
    "df = df.withColumn(\n",
    "    \"Stock_symbol\",\n",
    "    F.upper(\n",
    "        F.regexp_extract(\n",
    "            F.input_file_name(),\n",
    "            r\"([^/]+)\\.csv$\",\n",
    "            1\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f978c3f0-9855-4638-952d-385449d05d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the stock price DataFrame to S3 in Parquet format, partitioned by stock symbol\n",
    "df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"Stock_symbol\") \\\n",
    "    .parquet(\"s3a://fnf-bucket/silver/stock_price_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf383cc-9e9d-4509-9f07-63510e674169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
