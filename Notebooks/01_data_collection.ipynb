{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec1a284-bf1e-4a61-922d-e9947b020562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for AWS S3 and data handling\n",
    "import boto3\n",
    "import os\n",
    "from minio import Minio\n",
    "from huggingface_hub import list_repo_files\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08da68-4230-4de6-bd70-9596e3cf31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for dataset and MinIO\n",
    "DATASET_ID = \"Zihan1004/FNSPID\"\n",
    "S3_BUCKET = \"fnf-bucket\"\n",
    "\n",
    "# MinIO Configuration\n",
    "MINIO_ENDPOINT = \"minio:9000\"\n",
    "MINIO_ACCESS_KEY = \"minioadmin\"\n",
    "MINIO_SECRET_KEY = \"minioadmin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4b35ce-b5a7-4080-a3ff-1ac6186afb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 client for interacting with MinIO\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://minio:9000',\n",
    "    aws_access_key_id=MINIO_ACCESS_KEY,\n",
    "    aws_secret_access_key=MINIO_SECRET_KEY,\n",
    "    use_ssl=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5fef0-581b-4522-9c19-471cdfd76a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'fnf-bucket' already exists\n"
     ]
    }
   ],
   "source": [
    "# Check if the S3 bucket exists, create it if not\n",
    "try:\n",
    "    s3_client.head_bucket(Bucket=S3_BUCKET)\n",
    "    print(f\"Bucket '{S3_BUCKET}' already exists\")\n",
    "except:\n",
    "    s3_client.create_bucket(Bucket=S3_BUCKET)\n",
    "    print(f\"Created bucket '{S3_BUCKET}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d76789-1b02-4a9b-b2f0-0da90f957c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetching file list from Hugging Face...\n"
     ]
    }
   ],
   "source": [
    "# Fetch file list from Hugging Face dataset repository\n",
    "print(\"\\nFetching file list from Hugging Face...\")\n",
    "files = list_repo_files(\n",
    "    repo_id=DATASET_ID,\n",
    "    repo_type=\"dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce508178-0f71-4906-ac73-700f8a6a3bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['README.md',\n",
       " 'Stock_news/All_external.csv',\n",
       " 'Stock_news/nasdaq_exteral_data.csv',\n",
       " 'Stock_price/full_history.zip']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the fetched files\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c12f3a-5519-49e7-9b4a-3e844b4d5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and upload news data to S3\n",
    "def get_news_data():\n",
    "    hf_url = f\"https://huggingface.co/datasets/{DATASET_ID}/resolve/main/Stock_news/nasdaq_exteral_data.csv\"\n",
    "    response = requests.get(hf_url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    s3_key = \"bronze/stock_news/nasdaq_exteral_data.csv\"\n",
    "    try:\n",
    "        s3_client.upload_fileobj(\n",
    "            response.raw,\n",
    "            S3_BUCKET,\n",
    "            s3_key\n",
    "        )\n",
    "        print(\"Upload successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to S3: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321fa30-db7a-4c14-bca9-87ad18fde7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful!\n"
     ]
    }
   ],
   "source": [
    "# Call the function to get news data\n",
    "get_news_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16200c66-5342-41af-adfd-57db77c5047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and upload stock price data to S3\n",
    "def get_stocks_data():\n",
    "    hf_url = f\"https://huggingface.co/datasets/{DATASET_ID}/resolve/main/Stock_price/full_history.zip\"\n",
    "    response = requests.get(hf_url, stream=True)\n",
    "    response.raise_for_status()\n",
    "    s3_key = \"bronze/stock_price/full_history.zip\"\n",
    "    try:\n",
    "        s3_client.upload_fileobj(\n",
    "            response.raw,\n",
    "            S3_BUCKET,\n",
    "            s3_key\n",
    "        )\n",
    "        print(\"Upload successful!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading to S3: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88860047-044a-42ae-ba2c-7d4b08b92700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload successful!\n"
     ]
    }
   ],
   "source": [
    "# Call the function to get stock data\n",
    "get_stocks_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6962580-8bc8-42fd-8b6d-1bb4d9c2dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional libraries for data processing\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286dab1-e57f-4158-b940-7ac601bac321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define URL for S&P 500 companies list and set headers for the request\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea91637-ca6e-42c8-97d7-bcf1ee789ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the S&P 500 companies table from Wikipedia\n",
    "response = requests.get(url, headers=headers)\n",
    "tables = pd.read_html(StringIO(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a24c6-d0e1-48c7-917d-1877b9701697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first table which contains the S&P 500 companies\n",
    "sp500_table = tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ba92e0-c095-41c2-8226-601d7e824e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of stock symbols from the S&P 500 table\n",
    "stock_list = sp500_table['Symbol'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8dc34-b32a-44c6-88dd-064bd541c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract CSV files from a ZIP archive in S3\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def extract_zip(stock_list):\n",
    "    # Convert to set for faster lookup\n",
    "    stock_set = set(stock_list)\n",
    "\n",
    "    # Get the object and read from the Body\n",
    "    response = s3_client.get_object(\n",
    "        Bucket=S3_BUCKET,\n",
    "        Key=\"bronze/stock_price/full_history.zip\"\n",
    "    )\n",
    "    zip_bytes = BytesIO(response['Body'].read())\n",
    "\n",
    "    with zipfile.ZipFile(zip_bytes, \"r\") as z:\n",
    "        file_list = [\n",
    "            name for name in z.namelist()\n",
    "            if \"__MACOSX\" not in name and name.endswith(\".csv\")\n",
    "        ]\n",
    "\n",
    "        for name in tqdm(file_list, desc=\"Extracting ZIP\", unit=\"file\"):\n",
    "            # Extract stock symbol from filename\n",
    "            stock_symbol = os.path.splitext(os.path.basename(name))[0].upper()\n",
    "\n",
    "            # Skip files not in stock_list\n",
    "            if stock_symbol not in stock_set:\n",
    "                continue\n",
    "\n",
    "            file_data = z.read(name)\n",
    "\n",
    "            s3_client.put_object(\n",
    "                Bucket=S3_BUCKET,\n",
    "                Key=f\"bronze/stock_price/{name}\",\n",
    "                Body=BytesIO(file_data),\n",
    "                ContentLength=len(file_data)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0206f98-41a2-4317-a6ce-e540262742fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting ZIP: 100%|██████████| 7693/7693 [01:09<00:00, 111.23file/s]\n"
     ]
    }
   ],
   "source": [
    "# Call the function to extract stock data from the ZIP file\n",
    "extract_zip(stock_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
